{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOo/Nquiw3F9hMTTDXBFDnI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abinaya-512/LangGraph/blob/main/Copy_of_Untitled50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HVFl5_p8Hv0",
        "outputId": "6f556ce5-f092-41ef-fcc1-618485f1ef01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-1.0.3-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain\n",
            "  Downloading langchain-1.0.7-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Collecting openai\n",
            "  Downloading openai-2.8.1-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.79)\n",
            "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-1.0.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.10)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Collecting langchain-core>=0.1 (from langgraph)\n",
            "  Downloading langchain_core-1.0.5-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.4.42)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Downloading langgraph-1.0.3-py3-none-any.whl (156 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-1.0.7-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.7/93.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-2.8.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-1.0.5-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.5/471.5 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-1.0.4-py3-none-any.whl (34 kB)\n",
            "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.3/208.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, openai, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph, langchain\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.109.1\n",
            "    Uninstalling openai-1.109.1:\n",
            "      Successfully uninstalled openai-1.109.1\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.79\n",
            "    Uninstalling langchain-core-0.3.79:\n",
            "      Successfully uninstalled langchain-core-0.3.79\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.27\n",
            "    Uninstalling langchain-0.3.27:\n",
            "      Successfully uninstalled langchain-0.3.27\n",
            "Successfully installed langchain-1.0.7 langchain-core-1.0.5 langgraph-1.0.3 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.4 langgraph-sdk-0.2.9 openai-2.8.1 ormsgpack-1.12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langgraph langchain openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Literal, Dict, Any, Callable, Optional, List, Tuple\n",
        "import inspect\n",
        "import sys\n",
        "\n",
        "# -----------------------------\n",
        "# 0) Try to import langgraph; if unavailable, use a Mock implementation\n",
        "# -----------------------------\n",
        "try:\n",
        "    from langgraph.graph import StateGraph\n",
        "    from langgraph.checkpoint.memory import MemorySaver\n",
        "    LANGGRAPH_AVAILABLE = True\n",
        "except Exception as e:\n",
        "    LANGGRAPH_AVAILABLE = False\n",
        "\n",
        "    # Minimal Mock classes to emulate the behavior needed for the tutorial.\n",
        "    class MemorySaver:\n",
        "        def __init__(self):\n",
        "            self.storage = []\n",
        "        def save(self, state: Dict[str, Any]):\n",
        "            self.storage.append(dict(state))\n",
        "        def list(self):\n",
        "            return list(self.storage)\n",
        "\n",
        "    class CompiledMockGraph:\n",
        "        def __init__(self, nodes: Dict[str, Callable], edges: Dict[str, Any], entry: str, finish: str, checkpointer: Optional[MemorySaver]):\n",
        "            self.nodes = nodes\n",
        "            self.edges = edges\n",
        "            self.entry = entry\n",
        "            self.finish = finish\n",
        "            self.checkpointer = checkpointer\n",
        "\n",
        "        def invoke(self, state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "            # simple synchronous traversal\n",
        "            current = self.entry\n",
        "            visited = []\n",
        "            while True:\n",
        "                visited.append(current)\n",
        "                node_fn = self.nodes[current]\n",
        "                state = node_fn(state)\n",
        "                # checkpoint\n",
        "                if self.checkpointer is not None:\n",
        "                    self.checkpointer.save(state)\n",
        "                # finish condition\n",
        "                if current == self.finish:\n",
        "                    break\n",
        "                # determine next\n",
        "                transition = self.edges.get(current)\n",
        "                if transition is None:\n",
        "                    raise RuntimeError(f\"No transition defined from node: {current}\")\n",
        "                # transition may be a string (deterministic), or callable router\n",
        "                if isinstance(transition, str):\n",
        "                    next_node = transition\n",
        "                elif callable(transition):\n",
        "                    next_node = transition(state)\n",
        "                else:\n",
        "                    raise RuntimeError(f\"Unknown transition type from {current}: {transition}\")\n",
        "                if next_node not in self.nodes:\n",
        "                    raise ValueError(f\"Found edge ending at unknown node `{next_node}`\")\n",
        "                current = next_node\n",
        "            return state\n",
        "\n",
        "    class StateGraph:\n",
        "        def __init__(self, schema: Any = None):\n",
        "            self._nodes: Dict[str, Callable] = {}\n",
        "            # edges maps start_node -> either end_node_name or routing_fn\n",
        "            self._edges: Dict[str, Any] = {}\n",
        "            self._entry: Optional[str] = None\n",
        "            self._finish: Optional[str] = None\n",
        "\n",
        "        def add_node(self, name: str, fn: Callable):\n",
        "            self._nodes[name] = fn\n",
        "\n",
        "        def add_edge(self, start: str, end: str):\n",
        "            # store deterministic edge\n",
        "            self._edges[start] = end\n",
        "\n",
        "        def add_conditional_edges(self, start: str, router: Callable[[Dict[str, Any]], Any]):\n",
        "            self._edges[start] = router\n",
        "\n",
        "        def set_entry_point(self, name: str):\n",
        "            self._entry = name\n",
        "\n",
        "        def set_finish_point(self, name: str):\n",
        "            self._finish = name\n",
        "\n",
        "        # compile returns an object with invoke(state)\n",
        "        def compile(self, checkpointer: Optional[MemorySaver] = None, **kwargs):\n",
        "            # validate\n",
        "            all_targets = set()\n",
        "            for v in self._edges.values():\n",
        "                if isinstance(v, str):\n",
        "                    all_targets.add(v)\n",
        "                elif callable(v):\n",
        "                    # we cannot statically know the return set; skip\n",
        "                    pass\n",
        "            for target in all_targets:\n",
        "                if target not in self._nodes:\n",
        "                    raise ValueError(f\"Found edge ending at unknown node `{target}`\")\n",
        "            if self._entry is None or self._finish is None:\n",
        "                raise RuntimeError(\"Entry and finish points must be set\")\n",
        "            return CompiledMockGraph(self._nodes, self._edges, self._entry, self._finish, checkpointer)\n",
        "\n",
        "# -----------------------------\n",
        "# 1) Define the State schema\n",
        "# -----------------------------\n",
        "class MyState(TypedDict, total=False):\n",
        "    question: str\n",
        "    docs: str\n",
        "    answer: str\n",
        "    use_retriever: bool\n",
        "\n",
        "# -----------------------------\n",
        "# 2) Define nodes\n",
        "# -----------------------------\n",
        "\n",
        "def classifier_node(state: MyState) -> MyState:\n",
        "    q = state.get(\"question\", \"\").lower()\n",
        "    keywords = [\"who\", \"when\", \"where\", \"facts\", \"what is\", \"define\"]\n",
        "    state[\"use_retriever\"] = any(k in q for k in keywords)\n",
        "    return state\n",
        "\n",
        "\n",
        "def retriever_node(state: MyState) -> MyState:\n",
        "    question = state.get(\"question\", \"\")\n",
        "    state[\"docs\"] = f\"[Retrieved context for: {question}] Relevant facts...\"\n",
        "    return state\n",
        "\n",
        "\n",
        "def generator_node(state: MyState) -> MyState:\n",
        "    q = state.get(\"question\", \"\")\n",
        "    docs = state.get(\"docs\")\n",
        "    if docs:\n",
        "        state[\"answer\"] = f\"Answer (with docs): Based on context: {docs} --> Answer to '{q}'\"\n",
        "    else:\n",
        "        state[\"answer\"] = f\"Answer (no docs): A short answer to '{q}'\"\n",
        "    return state\n",
        "\n",
        "# -----------------------------\n",
        "# 3) Assemble StateGraph\n",
        "# -----------------------------\n",
        "workflow = StateGraph(MyState)\n",
        "workflow.add_node(\"classifier\", classifier_node)\n",
        "workflow.add_node(\"retriever\", retriever_node)\n",
        "workflow.add_node(\"generator\", generator_node)\n",
        "workflow.set_entry_point(\"classifier\")\n",
        "\n",
        "# -----------------------------\n",
        "# 4) Conditional routing\n",
        "# -----------------------------\n",
        "from typing import cast\n",
        "\n",
        "def route_after_classify(state: MyState) -> Literal[\"retriever\", \"generator\"]:\n",
        "    return \"retriever\" if state.get(\"use_retriever\") else \"generator\"\n",
        "\n",
        "workflow.add_conditional_edges(\"classifier\", route_after_classify)\n",
        "workflow.add_edge(\"retriever\", \"generator\")\n",
        "workflow.set_finish_point(\"generator\")\n",
        "\n",
        "# -----------------------------\n",
        "# 5) Diagnostics before compiling\n",
        "# -----------------------------\n",
        "print(\"--- DIAGNOSTICS: nodes registered in workflow ---\")\n",
        "try:\n",
        "    nodes = getattr(workflow, \"nodes\", None) or getattr(workflow, \"_nodes\", None)\n",
        "    if isinstance(nodes, dict):\n",
        "        print(\"nodes:\", list(nodes.keys()))\n",
        "    else:\n",
        "        print(\"nodes object:\", nodes)\n",
        "except Exception as e:\n",
        "    print(\"could not read workflow.nodes:\", e)\n",
        "\n",
        "print(\"--- DIAGNOSTICS: edges registered in workflow ---\")\n",
        "try:\n",
        "    edges = (\n",
        "        getattr(workflow, \"edges\", None)\n",
        "        or getattr(workflow, \"_edges\", None)\n",
        "        or getattr(workflow, \"_transitions\", None)\n",
        "        or getattr(workflow, \"_edges\", None)\n",
        "    )\n",
        "    print(\"edges:\", edges)\n",
        "except Exception as e:\n",
        "    print(\"could not read workflow.edges:\", e)\n",
        "\n",
        "print(\"If any of the printed 'edges' show a <function, remove the bad add_edge call from your environment or restart the kernel.\")\n",
        "\n",
        "# -----------------------------\n",
        "# 6) Compile with MemorySaver\n",
        "# -----------------------------\n",
        "memory = MemorySaver()\n",
        "try:\n",
        "    graph = workflow.compile(checkpointer=memory)\n",
        "    print(\"Compiled graph successfully.\")\n",
        "except Exception as exc:\n",
        "    print(\"Compile failed with error:\", exc)\n",
        "    raise\n",
        "\n",
        "# -----------------------------\n",
        "# 7) Run examples and tests\n",
        "# -----------------------------\n",
        "\n",
        "def run_example(question: str, thread_id: str) -> Dict[str, Any]:\n",
        "    initial_state: MyState = {\"question\": question}\n",
        "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
        "    final_state = graph.invoke(initial_state, config=config)\n",
        "    print(\"QUESTION:\", question)\n",
        "    print(\"USE_RETRIEVER:\", final_state.get(\"use_retriever\"))\n",
        "    print(\"DOCS:\", final_state.get(\"docs\"))\n",
        "    print(\"ANSWER:\", final_state.get(\"answer\"))\n",
        "    return final_state\n",
        "\n",
        "# Minimal tests (assertions) to ensure behavior is consistent.\n",
        "# Add more tests here if you want to exercise other branches.\n",
        "\n",
        "def _run_tests():\n",
        "    print(\"--- Running quick tests ---\")\n",
        "    s1 = run_example(\"Who invented the telephone?\", thread_id=\"test_thread_1\")\n",
        "    assert s1.get(\"use_retriever\") is True, \"Expected retriever to be used for factual question\"\n",
        "    assert \"Retrieved context for\" in (s1.get(\"docs\") or \"\"), \"Expected docs to be populated\"\n",
        "\n",
        "    s2 = run_example(\"Give a short analogy for recursion.\", thread_id=\"test_thread_2\")\n",
        "    assert s2.get(\"use_retriever\") is False, \"Expected retriever NOT to be used for opinion question\"\n",
        "    assert s2.get(\"docs\") is None or s2.get(\"docs\") == \"\", \"Expected no docs for short opinion question\"\n",
        "\n",
        "    s3 = run_example(\"What is the capital of France?\", thread_id=\"test_thread_3\")\n",
        "    assert s3.get(\"use_retriever\") is True\n",
        "\n",
        "    print(\"All tests passed.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"LANGGRAPH_AVAILABLE={LANGGRAPH_AVAILABLE}\")\n",
        "    _run_tests()\n",
        "\n",
        "# End of file\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKLslfqVImrm",
        "outputId": "67bdedcf-ea06-4690-cbc3-6aa6356c8858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- DIAGNOSTICS: nodes registered in workflow ---\n",
            "nodes: ['classifier', 'retriever', 'generator']\n",
            "--- DIAGNOSTICS: edges registered in workflow ---\n",
            "edges: {('generator', '__end__'), ('__start__', 'classifier'), ('retriever', 'generator')}\n",
            "If any of the printed 'edges' show a <function, remove the bad add_edge call from your environment or restart the kernel.\n",
            "Compiled graph successfully.\n",
            "LANGGRAPH_AVAILABLE=True\n",
            "--- Running quick tests ---\n",
            "QUESTION: Who invented the telephone?\n",
            "USE_RETRIEVER: True\n",
            "DOCS: [Retrieved context for: Who invented the telephone?] Relevant facts...\n",
            "ANSWER: Answer (with docs): Based on context: [Retrieved context for: Who invented the telephone?] Relevant facts... --> Answer to 'Who invented the telephone?'\n",
            "QUESTION: Give a short analogy for recursion.\n",
            "USE_RETRIEVER: False\n",
            "DOCS: None\n",
            "ANSWER: Answer (no docs): A short answer to 'Give a short analogy for recursion.'\n",
            "QUESTION: What is the capital of France?\n",
            "USE_RETRIEVER: True\n",
            "DOCS: [Retrieved context for: What is the capital of France?] Relevant facts...\n",
            "ANSWER: Answer (with docs): Based on context: [Retrieved context for: What is the capital of France?] Relevant facts... --> Answer to 'What is the capital of France?'\n",
            "All tests passed.\n"
          ]
        }
      ]
    }
  ]
}